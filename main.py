import os
from dotenv import load_dotenv
from langchain_deepseek import ChatDeepSeek
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import LLMChain, SequentialChain
load_dotenv()
api_key = os.getenv("DEEPSEEK_API_KEY")
if not api_key:
    raise ValueError("è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® DEEPSEEK_API_KEY")

# åˆå§‹åŒ– ChatDeepSeek æ¨¡å‹
llm = ChatDeepSeek(
    model="deepseek-chat",  # æˆ–è€…ä½¿ç”¨å…¶ä»–å¯ç”¨çš„æ¨¡å‹åç§°
    temperature=0.7,
    max_tokens=512,
    timeout=30,
    max_retries=2,
    api_key=api_key,  # å¦‚æœæœªè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¯ä»¥åœ¨æ­¤ç›´æ¥æä¾› API å¯†é’¥
)

# # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
# messages = [
#     SystemMessage(content="Translate the following from English into Italian"),
#     HumanMessage(content="hi are you ok?")
# ]

# Step 1: ç¿»è¯‘è‹±æ–‡æ–‡ç« ä¸ºä¸­æ–‡
translate_prompt = ChatPromptTemplate.from_template(
    "è¯·å°†ä»¥ä¸‹è‹±æ–‡å†…å®¹ç¿»è¯‘æˆä¸­æ–‡ï¼š\n\n{article}"
)
translate_chain = LLMChain(llm=llm, prompt=translate_prompt, output_key="translated")
# Step 2: ä¸ºä¸­æ–‡æ–‡ç« ç”Ÿæˆæ ‡é¢˜ï¼ˆ15 å­—ä»¥å†…ï¼‰
title_prompt = ChatPromptTemplate.from_template(
    "ä»¥ä¸‹æ˜¯ä¸­æ–‡æ–‡ç« å†…å®¹ï¼š{translated}\nè¯·ä¸ºè¿™ç¯‡æ–‡ç« èµ·ä¸€ä¸ªå¸å¼•äººçš„ä¸­æ–‡æ ‡é¢˜ï¼ˆä¸è¶…è¿‡15ä¸ªå­—ï¼‰ï¼š"
)
title_chain = LLMChain(llm=llm, prompt=title_prompt, output_key="title")



article_chain = SequentialChain(
    chains=[translate_chain, title_chain],
    input_variables=["article"],
    output_variables=["translated", "title"],
    verbose=True
)
# ç¤ºä¾‹è‹±æ–‡è¾“å…¥
article_text = """
LangChain is an open-source framework that simplifies building applications with large language models. 
It supports features like memory, chaining, agents, and retrieval, allowing developers to compose complex workflows easily.
"""

# æ‰§è¡Œé“¾å¼å¤„ç†
result = article_chain.invoke({"article": article_text})

# è¾“å‡ºç»“æœ
print("\nğŸ“˜ ä¸­æ–‡ç¿»è¯‘ï¼š\n", result["translated"])
print("\nğŸ·ï¸ ç”Ÿæˆæ ‡é¢˜ï¼š", result["title"])
